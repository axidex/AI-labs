from tokenize import PlainToken
import numpy as np
import random
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

x=[0.0,0.6122448979591837,1.2244897959183674,1.836734693877551,2.4489795918367347,3.0612244897959187,3.673469387755102,4.285714285714286,4.8979591836734695,5.510204081632653,6.122448979591837,6.73469387755102,7.346938775510204,7.959183673469388,8.571428571428571,9.183673469387756,9.795918367346939,10.408163265306122,11.020408163265307,11.63265306122449,12.244897959183675,12.857142857142858,13.46938775510204,14.081632653061225,14.693877551020408,15.306122448979592,15.918367346938776,16.53061224489796,17.142857142857142,17.755102040816325,18.367346938775512,18.979591836734695,19.591836734693878,20.20408163265306,20.816326530612244,21.42857142857143,22.040816326530614,22.653061224489797,23.26530612244898,23.877551020408163,24.48979591836735,25.102040816326532,25.714285714285715,26.3265306122449,26.93877551020408,27.551020408163264,28.16326530612245,28.775510204081634,29.387755102040817,30.0]
y=[103.09532681036755,60.64960432687138,82.79483746232057,62.647110840536286,124.05925619404826,96.43828219023422,163.4763969980349,158.19304994371362,154.0288700910815,119.320495883008,130.75920827520008,155.8336870549172,172.12476348195835,142.97011987387154,152.8734390643684,116.54061936340476,121.22974679291919,138.24746425964807,109.7518957346999,177.3790353912938,127.14932042111192,110.0352943908648,196.1654513274892,146.92854909407683,197.06721054750625,149.29111065595092,171.9478101455099,198.4350773302673,119.34142026876306,204.6535999568399,160.1437312015482,203.88942920668063,152.89914630499246,216.73415864330298,142.58316573321767,220.10106549068115,187.0941705779788,139.56514227070937,126.41483140859235,201.84727785750437,162.4312786891109,183.83963018644098,161.8534384420994,138.51260296265937,190.2517740261142,179.13481699510126,223.59552589940637,234.7503986235846,153.7276977311854,155.34302733656108]
#x=[0.0,0.30303030303030304,0.6060606060606061,0.9090909090909092,1.2121212121212122,1.5151515151515151,1.8181818181818183,2.121212121212121,2.4242424242424243,2.7272727272727275,3.0303030303030303,3.3333333333333335,3.6363636363636367,3.9393939393939394,4.242424242424242,4.545454545454546,4.848484848484849,5.151515151515151,5.454545454545455,5.757575757575758,6.0606060606060606,6.363636363636364,6.666666666666667,6.96969696969697,7.272727272727273,7.575757575757576,7.878787878787879,8.181818181818182,8.484848484848484,8.787878787878789,9.090909090909092,9.393939393939394,9.696969696969697,10.0,10.303030303030303,10.606060606060606,10.90909090909091,11.212121212121213,11.515151515151516,11.818181818181818,12.121212121212121,12.424242424242424,12.727272727272728,13.030303030303031,13.333333333333334,13.636363636363637,13.93939393939394,14.242424242424242,14.545454545454547,14.84848484848485,15.151515151515152,15.454545454545455,15.757575757575758,16.060606060606062,16.363636363636363,16.666666666666668,16.96969696969697,17.272727272727273,17.575757575757578,17.87878787878788,18.181818181818183,18.484848484848484,18.78787878787879,19.09090909090909,19.393939393939394,19.6969696969697,20.0,20.303030303030305,20.606060606060606,20.90909090909091,21.21212121212121,21.515151515151516,21.81818181818182,22.12121212121212,22.424242424242426,22.727272727272727,23.03030303030303,23.333333333333336,23.636363636363637,23.93939393939394,24.242424242424242,24.545454545454547,24.848484848484848,25.151515151515152,25.454545454545457,25.757575757575758,26.060606060606062,26.363636363636363,26.666666666666668,26.96969696969697,27.272727272727273,27.575757575757578,27.87878787878788,28.181818181818183,28.484848484848484,28.78787878787879,29.090909090909093,29.393939393939394,29.6969696969697,30.0]
#y=[107.17891751982046,93.26408363662338,91.08862757367106,180.8561635962477,201.7366751917977,119.31123301139587,110.15873617600263,85.2868548165694,113.27484172210508,151.42837538909262,136.85918898812952,107.06966547675567,196.3718826042208,93.67901453437852,209.47810513677206,96.07591695310593,103.41605549520702,103.45484435507186,140.74483442393745,191.47530915507852,115.23881352713805,215.45496124480042,187.55266118448537,152.47303639652858,142.09875170724067,219.90612570521827,93.23124139913111,165.47110992325435,237.6311588638206,185.49337664292983,96.57722037599925,214.56443524215337,172.17740520123465,119.9340632936244,151.4514290872419,246.13854770784366,137.1871775406439,228.88420640649667,150.73664151783748,223.10609678131428,146.16272658014748,168.8091957055989,139.32432550722152,138.44328789508674,212.85398389013767,143.93587589093514,213.42833295419922,217.22945282930993,229.58553015771074,208.04919830685873,218.237640079826,203.61690629527095,264.5771449356479,266.56093500449873,280.7725147456776,227.77661886178936,234.05562744976802,218.4053340257764,233.93746631595843,305.8734161562795,184.42936840339914,249.65737854186526,292.1604684594648,267.7582205225242,194.80605063867222,271.3074066713623,293.33383806018117,248.94779492039876,213.42101072146303,269.178133146772,262.32184155846227,352.1004711229692,342.9053673375964,278.2028690207454,338.94459789384183,299.40818880552575,236.0131680518689,288.9141398367215,245.40331255572818,285.87367455641646,335.27018539472664,347.1991360548786,303.0929631345275,420.52091533680243,324.111113384735,384.43464216578644,364.14086775517205,333.6181597660758,410.3703253435683,455.50249249040974,378.26950958992796,344.7831475435914,461.44033140447266,437.9061716913492,486.13568402020803,362.2768069028956,445.0292488554805,422.88982140404045,421.49282021666676,395.3578098424966]

J_train=[]
J_test=[]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=19)
for i in range(10):
    theta = np.polyfit(x_train,y_train,i)
    y_pred_train=np.polyval(theta,x_train)
    J_train.append(sum((y_train-y_pred_train)**2))

    y_pred_test=np.polyval(theta,x_test)
    J_test.append(sum((y_test-y_pred_test)**2))


plt.plot(J_train, 'r')
plt.plot(J_test, 'b')

plt.show()
